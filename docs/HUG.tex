\documentclass[11pt]{article}

% --- PACCHETTI ---
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage[italian]{babel}
\usepackage{graphicx}
\usepackage{geometry}
\usepackage{xcolor}
\usepackage{changepage}
\usepackage{titlesec}
\usepackage{fancyhdr} % Per l'intestazione personalizzata
\usepackage{float}
\usepackage[none]{hyphenat}
\usepackage{parskip}
\usepackage[colorlinks=true,
    linkcolor=black, % L'indice resta nero
    urlcolor=black,   % I link web diventano blu
    citecolor=black]{hyperref}
\usepackage{color}
\usepackage{amsmath}

\geometry{top=2.5cm, bottom=2.5cm, left=2.5cm, right=2.5cm, headheight=40pt}

% --- DEFINIZIONE COLORI ---
\definecolor{HUGPurple}{HTML}{AE4FDD}

% --- CONFIGURAZIONE INTESTAZIONE (HEADER) ---
\pagestyle{fancy}
\fancyhf{} % Pulisce header e footer precedenti

% 1. Logo a sinistra (Dip-Inf)
\lhead{\includegraphics[height=1.2cm]{images/dip-Inf.png}}

\rhead{\footnotesize
Laurea Triennale in Informatica - Università di Salerno \\
Corso di Machine Learning - Prof. G. Polese - Prof.ssa L. Caruccio}

% 3. Numero di pagina in basso al centro
\cfoot{\thepage}

\fancypagestyle{plain}{
    \fancyhf{}
    \lhead{\includegraphics[height=1.2cm]{images/dip-Inf.png}}
    \rhead{\footnotesize Laurea Triennale in Informatica - Università di Salerno \\ Corso di Machine Learning - Prof. G. Polese - Prof.ssa L. Caruccio}
    \cfoot{\thepage}
}

% --- INIZIO DOCUMENTO ---
\begin{document}

    % ==========================================
    %               COPERTINA
    % ==========================================
    \begin{titlepage}
        \thispagestyle{empty}
        \centering

        % Testo Istituzionale (Come nella versione originale)
        \Large UNIVERSITÀ DEGLI STUDI DI SALERNO \\[0.5cm]
        \Large Corso di Laurea in Informatica \\
        \Large Machine Learning \\[1cm]

        \includegraphics[width=0.5\textwidth]{images/logo-HUG} \\[0.4cm]

        % Titolo Progetto
        \Huge \textbf{HUG}\\[0.5cm]

        % Autori
        \Large
        \textbf{Gruppo di Progetto:} \\[0.5cm]
        Andrea Generale (Mat. 0512119134) \\[0.3cm]
        Samuele Nacchia (Mat. 0512119128) \\[0.8cm]

        % Link al repository
        \large
        \textbf{Link al repository:} \href{https://github.com/samueleNacchia/HUG}{https://github.com/samueleNacchia/HUG} \\[0.8cm]

        % Logo Unisa in basso
        \includegraphics[width=0.2\textwidth]{images/unisa}

        \vfill
        \large Anno Accademico 2025/2026
    \end{titlepage}

    \newpage

    % ==========================================
    %               INDICE
    % ==========================================
    \tableofcontents
    \newpage

    % ==========================================
    %               CONTENUTO
    % ==========================================

    \section{Introduzione}

        Il benessere psicologico degli studenti universitari rappresenta una tematica di crescente rilevanza nel
        panorama accademico e sanitario. Il percorso universitario, spesso caratterizzato da elevate pressioni
        performative, transizioni sociali significative e incertezza verso il futuro, costituisce una fase critica
        che può favorire l'insorgenza di disturbi dell'umore, tra cui la depressione.\newline
        Tale disagio, se trascurato, può aggravarsi fino a livelli insostenibili, portando nei casi più drammatici a
        gesti estremi.


    \subsection{Sistema attuale}

        Attualmente, l’individuazione di studenti universitari a rischio di depressione avviene
        principalmente tramite autosegnalazione o osservazioni indirette da parte di docenti e tutor.\newline
        I servizi di supporto psicologico operano in maniera reattiva, intervenendo solo quando il disagio è
        già esplicitamente manifestato. Non sono presenti strumenti automatici di analisi o predizione basati sui dati,
        rendendo difficile un’identificazione precoce e sistematica degli studenti potenzialmente vulnerabili.


    \subsection{Obiettivi}

        Il sistema HUG - Health Understanding Guide è stato progettato con l’obiettivo
        di fornire un supporto proattivo nella rilevazione precoce della depressione tra gli studenti universitari,
        al fine di favorire interventi tempestivi e mirati da parte dell'università e degli psicologi dell'ateneo.
        HUG è un alleato nel monitoraggio del benessere psicologico, ma non sostituisce il lavoro degli esperti.
        Il sistema non ha l'intento di diagnosticare o curare la depressione, ma piuttosto di identificare segnali di
        rischio che possano indicare uno stato di disagio emotivo o mentale, permettendo una valutazione iniziale
        della salute psicologica degli studenti.


    % ------------------------------------------

    \newpage

    \section{Descrizione agente}
    Il sistema \textit{HUG} è modellato come un agente intelligente di tipo
    \textbf{classificatore}, progettato per supportare l’individuazione precoce
    di potenziali stati di disagio psicologico negli studenti universitari.
    L’agente analizza le risposte fornite dagli studenti tramite questionari
    psicologici strutturati e produce una valutazione automatica del rischio
    di sintomi depressivi.

    \subsection{Specifica PEAS}
    Di seguito è riportata la descrizione PEAS dell'ambiente operativo in forma tabellare.

    \begin{table}[H]
        \centering
        \renewcommand{\arraystretch}{1.5} % Spaziatura righe
        \begin{tabular}{|l|p{10cm}|}
            \hline
            \textbf{Componente} & \textbf{Descrizione} \\
            \hline
            \textbf{Performance} & La misura di performance del sistema si basa sulla capacità
                                   dell'agente di distinguere correttamente studenti inclini alla
                                   depressione e studenti non inclini, con particolare attenzione
                                   all'identificazione accurata della classe Depressione=True. \\

            \hline
            \textbf{Environment} & L'ambiente consiste negli studenti universitari, i quali
                                   completano un questionario psicologico per valutare il loro benessere emotivo. \\

            \hline
            \textbf{Actuators} & Gli attuatori consistono in un sistema di classificazione che
                                 assegna un'etichetta (\("\)Rischio Depressione Rilevato\("\) o \("\)Nessun Rischio Rilevato\("\)) e segnala
                                 gli studenti identificati come a rischio con una panoramica chiara dei diversi report.
                                 Questi attuatori permettono di attivare interventi per supportare gli studenti. \\

            \hline
            \textbf{Sensors} & I sensori consistono nelle risposte al questionario psicologico
                               fornito dagli studenti, che vengono analizzate dal sistema. \\
            \hline
        \end{tabular}
        \caption{Specifica PEAS dell'agente HUG}\label{tab:table}
    \end{table}


    \subsection{Specifiche dell'ambiente}

        L’ambiente operativo in cui agisce il sistema \textit{HUG}
        è costituito dall’insieme dei dati relativi agli studenti universitari, provenienti da questionari
        autocompilati. Il modello di machine learning interagisce con tale ambiente analizzando i dati disponibili
        al fine di stimare la presenza o meno del rischio di disagio psicologico.

        L’ambiente di HUG può essere classificato come segue:

        \begin{itemize}
            \item \textbf{Parzialmente osservabile}:
            l’agente non ha accesso diretto allo stato psicologico reale dello studente, ma solo a informazioni
            indirette e parziali, spesso soggettive e rumorose, come risposte a questionari.
            Di conseguenza, lo stato dell’ambiente non è completamente osservabile.

            \item \textbf{Non deterministico}:
            la relazione tra i dati osservabili e il reale stato emotivo dello studente non è deterministica.
            A parità di input possono corrispondere stati psicologici differenti, a causa di fattori esterni
            non completamente modellabili e dell’elevata variabilità individuale.

            \newpage
            \item \textbf{Episodico}:
            ogni valutazione prodotta dal sistema è indipendente dalle precedenti.\newline Il modello analizza le
            osservazioni raccolte in un determinato istante temporale senza mantenere uno stato interno che
            tenga traccia delle valutazioni passate. Ciascun episodio corrisponde pertanto a una singola
            compilazione del questionario, e la decisione non influenza né dipende da episodi futuri.

            \item \textbf{Statico}:
            durante l’elaborazione dei dati relativi a una singola compilazione del questionario, l’ambiente
            non cambia: le percezioni fornite all’agente e lo stato interno considerato restano invariati fino al
            termine dell’analisi. Eventuali variazioni nello stato emotivo dello studente o nei dati disponibili
            si verificano solo tra episodi distinti, e non influenzano il processo decisionale in corso.

            \item \textbf{Discreto}:
            poiché il sistema produce esclusivamente una classificazione binaria e opera su percezioni,
            stati e azioni discreti

            \item \textbf{Singolo agente}:
            il sistema HUG opera come agente singolo e non interagisce direttamente con altri agenti
            intelligenti. Esso fornisce supporto decisionale a figure umane quali psicologi e servizi di
            supporto universitari, che rimangono responsabili degli interventi finali.
        \end{itemize}

    % ------------------------------------------

    \section{Individuazione dataset }
    Nella fase iniziale del progetto, sono state valutate due diverse strategie per l'acquisizione dei
    dati necessari all'addestramento del modello di Machine Learning:
    \begin{enumerate}
        \item \textbf{Creare} un dataset da zero, sottoponendo un questionario ad un campione di studenti;

        \item \textbf{Cercare} sulla rete un dataset già formato,
                    e adeguarlo alle nostre esigenze;

    \end{enumerate}

    Dopo un'analisi comparativa, la prima opzione è stata scartata a causa di limitazioni metodologiche
    critiche. In primo luogo, la raccolta di un numero di campioni statisticamente significativo avrebbe
    richiesto tempi eccessivamente lunghi.

    Tuttavia, l'ostacolo principale è rappresentato dalla \textbf{mancanza di un esperto di dominio}.\newline
    Per addestrare un modello di classificazione accurato, ogni record deve essere etichettato correttamente
    (es. "Depresso: Sì/No"). Senza la supervisione di un professionista in grado di valutare clinicamente
    le risposte dei candidati, il dataset prodotto sarebbe risultato privo di validità scientifica,
    rendendo il modello inaffidabile.

    Di conseguenza, si è deciso di procedere con la seconda soluzione, individuando sulla
    piattaforma \textbf{Kaggle} il dataset: \href{https://www.kaggle.com/datasets/adilshamim8/student-depression-dataset/data}{\textcolor{blue}{\underline{\textit{"Student Depression Dataset"}}}}


    \newpage

    \subsection{Punti di forza del dataset}
    La scelta è ricaduta su questo archivio per i seguenti motivi:
    \begin{itemize}
        \item \textbf{Varietà dei parametri:}
            Include fattori determinanti come la pressione accademica,
            la soddisfazione nello studio, le ore di sonno e la storia clinica familiare.
        \item \textbf{Ampiezza dei dati:} Le migliaia di osservazioni forniscono una base solida
            per l'addestramento, permettendo all'algoritmo di riconoscere pattern complessi con
            maggiore precisione.
    \end{itemize}

    % ------------------------------------------

    \subsection{Limiti del dataset}
    Tale dataset presenta i seguenti limiti:
    \begin{itemize}

        \item
        \textbf{Provenienza culturale}: Il dataset proviene da studenti indiani, e le esperienze psicologiche e
        comportamentali potrebbero differire da quelle degli studenti italiani, influenzando i risultati.

        \item
        \textbf{Fattori socio-culturali e accademici}: Sebbene il dataset descriva variabili psicologiche e
        comportamentali legate alla vita universitaria (che non sono specifiche di un singolo contesto nazionale),
        le dinamiche socio-culturali e accademiche in India potrebbero comunque influenzare la rilevazione del rischio di depressione.

        \item
        \textbf{Validità limitata}: Senza una validazione su dati italiani, il modello potrebbe non riflettere
        accuratamente il rischio di depressione tra gli studenti italiani.

    \end{itemize}

    Sebbene il dataset quindi sia stato raccolto su studenti indiani, le informazioni disponibili
    descrivono aspetti psicologici e comportamentali legati alla vita universitaria che non sono
    specifici di un singolo contesto nazionale. Il modello viene pertanto utilizzato come studio
    preliminare per valutare la fattibilità di un sistema predittivo del rischio di depressione,
    riconoscendo che una validazione su dati italiani reali sarebbe necessaria per un impiego operativo.


% ==========================================
%          DATA UNDERSTANDING
% ==========================================
    \section{Data Understanding}

    Prima di procedere con le  fasi di preparazione dei dati, è stata svolta una fase di \textit{data understanding},
    con l’obiettivo di comprendere la struttura del dataset, il significato delle variabili e la loro coerenza con il
    dominio applicativo del sistema.

    In questa fase sono state analizzate tutte le colonne del dataset, identificandone il ruolo e il tipo di
    informazione rappresentata. In particolare, le variabili sono state suddivise nelle seguenti categorie:

    \begin{itemize}
        \item \textbf{Variabili demografiche}: \textit{Gender}, \textit{Age};
        \item \textbf{Variabili psicologiche e autovalutative}: \textit{Academic Pressure}, \textit{Work Pressure}, \textit{Study Satisfaction}, \textit{Job Satisfaction}, \textit{Have you ever had suicidal thoughts?}, \textit{Family History of Mental Illness}, \textit{Financial Stress};
        \item \textbf{Variabili di contesto accademico e personale}: \textit{Degree}, \textit{Profession}, \textit{Work/Study Hours}, \textit{CGPA}, \textit{Sleep Duration}, \textit{Dietary Habits}, \textit{City}.
    \end{itemize}

    È stata inoltre individuata la variabile target del problema di classificazione, identificata nella colonna
    \textit{Depression}, che rappresenta se lo studente è a rischio di depressione.

    \paragraph{Descrizione semantica delle variabili}

    La Tabella~\ref{tab:semantic_features} riporta una breve descrizione semantica delle variabili presenti nel
    dataset, al fine di chiarirne il significato e il ruolo nel contesto del problema affrontato.

    \begin{table}[H]
        \centering
        \begin{tabular}{|l|p{10cm}|}
            \hline
            \textbf{Variabile} & \textbf{Descrizione semantica} \\
            \hline
            Gender & Genere dichiarato dallo studente. \\
            Age & Età dello studente espressa in anni. \\
            Academic Pressure & Livello di pressione percepita legata alle attività accademiche. \\
            Work Pressure & Livello di pressione percepita legata alle attività lavorative. \\
            Study Satisfaction & Livello di soddisfazione dello studente rispetto allo studio. \\
            Job Satisfaction & Livello di soddisfazione rispetto ad attività lavorative. \\
            CGPA & Media accademica di tutti i voti ottenuti nel percorso di studi. \\
            Work/Study Hours & Numero medio di ore dedicate quotidianamente a studio e lavoro. \\
            Sleep Duration & Durata media del sonno giornaliero dichiarata. \\
            Dietary Habits & Indicatore delle abitudini alimentari dichiarate. \\
            Degree & Livello di istruzione dichiarato dallo studente. \\
            Financial Stress & Livello di stress percepito legato alla situazione finanziaria. \\
            Have you ever had suicidal thoughts? & Indicatore della presenza di pensieri suicidari auto-riferiti. \\
            Family History of Mental Illness & Presenza di precedenti familiari di disturbi mentali. \\
            Profession & Stato occupazionale dichiarato (nel dataset: Student). \\
            City & Città di residenza dichiarata dallo studente. \\
            Depression & Variabile target che indica la presenza o assenza di depressione. \\
            \hline
        \end{tabular}
        \caption{Descrizione semantica delle variabili del dataset}
        \label{tab:semantic_features}
    \end{table}

    Questa fase di data understanding ha consentito di validare la coerenza del dataset rispetto all’obiettivo
    del sistema e di impostare correttamente l’analisi preliminare e le successive fasi di preparazione dei dati,
    senza introdurre modifiche al dataset originale.



    \subsection{Analisi preliminare del dataset}
    L’analisi preliminare del dataset per comprenderne la struttura e le principali caratteristiche statistiche
    si è concentrata su:

    \begin{itemize}
        \item controllo del bilanciamento dei dati.
        \item calcolo della dipendenza delle feature numeriche e categoriche dalla variabile target \textit{Depression};
        \item analisi delle distribuzioni delle feature numeriche e categoriche per identificare variabili sbilanciate o a bassa variabilità.
        \item identificazione di possibili data leakage.
    \end{itemize}

    \newpage

    \paragraph{Bilanciamento dei dati}
    La Tabella~\ref{tab:class_distribution_depression_pct} riporta la distribuzione delle osservazioni tra le due classi della variabile
    target \textit{Depression}, da cui si osserva un moderato sbilanciamento a favore della classe positiva.
    \begin{table}[h]
        \centering
        \caption{Distribuzione delle classi della variabile target \textit{Depression}}
        \label{tab:class_distribution_depression_pct}
        \begin{tabular}{lcc}
            \hline
            \textbf{Classe} & \textbf{Numero di elementi} & \textbf{Percentuale (\%)} \\
            \hline
            Depressi (1)      & 16336 & 58.55 \\
            Non depressi (0)  & 11565 & 41.45 \\
            \hline
            Totale            & 27901 & 100.00 \\
            \hline
        \end{tabular}
    \end{table}



    \paragraph{Dipendenza dalla variabile target}

    Per le feature numeriche, è stata calcolata la correlazione di Pearson con la variabile target.
    Per le feature categoriche, la dipendenza è stata stimata come la massima differenza
    tra le percentuali di studenti depressi e non depressi all'interno delle categorie di ciascuna variabile.
    In altre parole, indica quanto la presenza di una determinata categoria sia associata allo stato di depressione.

    I risultati principali sono i seguenti:

    \textbf{Correlazione delle feature numeriche con la target \textit{Depression}:}
    \begin{itemize}
        \item Academic Pressure: 0.475
        \item Age: -0.226
        \item Work/Study Hours: 0.209
        \item Study Satisfaction: -0.168
        \item CGPA: 0.022
        \item Job Satisfaction: -0.003
        \item Work Pressure: -0.003
        \item id: 0.001
    \end{itemize}

    \textbf{Correlazione delle feature categoriche con la target \textit{Depression}:}
    \begin{itemize}
        \item City: 1.000
        \item Profession: 1.000
        \item Financial Stress: 0.626
        \item Have you ever had suicidal thoughts ?: 0.581
        \item Degree: 0.415
        \item Dietary Habits: 0.415
        \item Sleep Duration: 0.290
        \item Family History of Mental Illness: 0.225
        \item Gender: 0.173
    \end{itemize}

    \paragraph{Analisi delle distribuzioni}

    Per ciascuna feature, oltre a valutare la correlazione o la dipendenza dalla target, è stata analizzata la distribuzione dei valori:

    \begin{itemize}
        \item \textbf{Feature numeriche}: sono state calcolate media, deviazione standard, skewness e kurtosis.
        Feature con skew > 1, kurtosis > 5 o deviazione standard molto bassa (<0.01) sono state considerate \textit{anomale},
        poiché potrebbero non fornire informazioni significative al modello.
        \item \textbf{Feature categoriche}: sono state valutate la numerosità delle categorie e la distribuzione percentuale.
        Variabili con una sola categoria o con una categoria dominante (>90\%) sono considerate sbilanciate e poco informative.
    \end{itemize}

    \paragraph{Data leakage}
    Al fine di verificare la presenza di potenziali fenomeni di data leakage, è stata analizzata separatamente la feature
    \textit{Have you ever had suicidal thoughts ?} tramite una tabella di contingenza normalizzata rispetto alla variabile
    target \textit{Depression}. I risultati mostrano una dipendenza estremamente marcata tra le due variabili, suggerendo che la
    feature possa fornire informazione quasi deterministica sulla classe target.

    \begin{table}[h]
        \centering
        \caption{Distribuzione percentuale della variabile \textit{Depression} in funzione della feature \textit{Have you ever had suicidal thoughts ?}}
        \label{tab:suicidal_thoughts_depression_pct}
        \begin{tabular}{lcc}
            \hline
            \textbf{Have you ever had suicidal thoughts ?} & \textbf{Depression = 0 (\%)} & \textbf{Depression = 1 (\%)} \\
            \hline
            No  & 76.8 & 23.2 \\
            Yes & 21.0 & 79.0 \\
            \hline
        \end{tabular}
    \end{table}

    \section{Data preparation}

    La preparazione del dataset è stata fatta con lo scopo di mantenere alcune variabili di contesto accademico,
    introducendo trasformazioni controllate volte a migliorarne l’interpretabilità e la trasferibilità
    nel contesto universitario di riferimento. In particolare, tale preparazione consente di analizzare
    l’effetto di una rappresentazione più informata dei dati, pur senza introdurre assunzioni forti o
    modifiche che alterino il significato originale delle informazioni.


    \subsection{Data cleaning}
    La fase di \textit{data cleaning} è finalizzata a rimuovere elementi potenzialmente dannosi per il processo
    di apprendimento del modello, con l’obiettivo di migliorare la qualità e l’affidabilità complessiva del dataset.
    Sono state eliminate le feature

    \begin{itemize}
        \item \textit{id}: attributo identificativo degli studenti, irrilevante per la predizione del rischio di depressione
        \item \textit{Have you ever had suicidal thoughts?}: considerata la natura semantica della feature,
        che rappresenta un sintomo clinico direttamente associato alla depressione e il rischio di performance
        artificialmente gonfiate, la variabile è stata identificata come leaky predictor ed esclusa dalla fase di modellazione.
    \end{itemize}


    \paragraph{Valori nulli}
    Dall’ispezione del dataset non sono emerse
    osservazioni con valori nulli, pertanto non si è resa necessaria alcuna operazione di imputazione o rimozione
    di record incompleti.

    \paragraph{Osservazioni duplicate}
    Anche in questo caso,
    non sono state individuate righe duplicate, confermando la coerenza e l’unicità delle istanze presenti nel dataset.

    \paragraph{Outlier}
    È stata inoltre condotta un’analisi dei valori anomali (\textit{outlier}) sulle variabili numeriche mediante
    il metodo dell’\textit{Interquartile Range} (IQR). Tale analisi ha evidenziato la presenza di 22 \textit{outlier}
    nella variabile \textit{Age}, riferibili a studenti con età significativamente superiore rispetto alla
    distribuzione centrale, 3 \textit{outlier} nella variabile \textit{Work Pressure}, 6 nella variabile
    \textit{CGPA} (corrispondenti a valori pari a zero) e 2 nella variabile \textit{Job Satisfaction}.

    Per quanto riguarda le variabili categoriche, sono state considerate come valori anomali quelli con
    una frequenza inferiore all’1\% del totale delle osservazioni. In base a questo criterio, sono stati
    individuati 31 \textit{outlier} nella variabile \textit{Profession}, 18 nella variabile
    \textit{Sleep Duration}, 12 nella variabile \textit{Dietary Habits} e 3 nella variabile
    \textit{Financial Stress}.

    Inoltre, sono state eliminate 35 occorrenze con valore \textit{Others} nella variabile categorica
    \textit{Degree}, in quanto poco rappresentative e potenzialmente distorsive per l’analisi.

    Complessivamente, il processo di identificazione e rimozione dei valori anomali ha comportato
    l’eliminazione di 132 osservazioni dal dataset, consentendo di ottenere un insieme di dati più coerente e
    rappresentativo ai fini delle successive analisi statistiche.


    \subsection{Feature engineering}

    \paragraph{Feature Trasformation - Age}

    La variabile continua \textit{Age} è stata discretizzata nella nuova feature \texttt{Age\_group}
    sulla base dell’analisi della sua distribuzione.
    Tale scelta è motivata dal fatto che la rappresentazione puramente numerica
    può amplificare il peso di osservazioni con età più elevate, introducendo effetti distorsivi nella
    stima del rischio.
    La categorizzazione dell’età consente invece di ridurre l’influenza di valori anomali, preservando al
    contempo l’informazione semantica associata alle diverse fasi della vita universitaria. Di seguito il
    grafico rappresenta il numero di osservazioni per ogni classe.

    \begin{figure}[h!]
        \centering
        \includegraphics[width=0.8\textwidth]{images/graphs/distribuzioniAge}
    \end{figure}

    \paragraph{Feature Transformation - Degree}
    La variabile \textit{Degree} descrive il livello di istruzione dichiarato dallo studente secondo il sistema educativo del paese di origine del dataset.
    Poiché tale rappresentazione risulta fortemente dipendente dal contesto accademico indiano e caratterizzata da un’elevata frammentazione delle categorie,
    è stata effettuata un’operazione di aggregazione in tre macro-categorie,
    basata esclusivamente sul livello di istruzione e non sul sistema universitario di riferimento.

    In particolare, i valori originali sono stati ricondotti alle seguenti categorie:
    \begin{itemize}
        \item \textbf{Diploma}: corrispondente al livello di istruzione secondaria superiore (es. \textit{Class 12});
        \item \textbf{Titolo di primo livello}: comprendente i titoli di livello bachelor;
        \item \textbf{Titolo di secondo livello}: comprendente i titoli di livello master e post-graduate.
    \end{itemize}

    Questa trasformazione consente di ridurre la dipendenza dal contesto accademico specifico del dataset,
    mantenendo al contempo un’informazione rilevante relativa al livello di istruzione dello studente.

    \paragraph{Feature Transformation - CGPA}

    La variabile \textit{CGPA} è espressa secondo una scala di valutazione specifica del sistema accademico di
    origine del dataset, nella quale valori più elevati corrispondono a prestazioni accademiche migliori.
    In particolare, secondo le specifiche del dataset, un valore di $10$ rappresenta il punteggio massimo,
    mentre un valore di $5$ corrisponde alla soglia minima di superamento.

    Al fine di rendere i valori maggiormente interpretabili nel contesto universitario italiano, la variabile è
    stata convertita in una rappresentazione su scala trentesimale. La conversione è stata effettuata mediante una
    trasformazione lineare, definita a partire dai punti di riferimento della scala ($10 \rightarrow 30$ e $5 \rightarrow 18$).
    La formula applicata è la seguente:

    \begin{equation}
        \text{CGPA}_{30} = 2.4 \cdot \text{CGPA} + 6
    \end{equation}

    Tale trasformazione preserva l’ordine e le proprietà statistiche della variabile originale e non altera la sua capacità
    predittiva, ma ha esclusivamente una finalità descrittiva e interpretativa.

    Nel dataset finale, la variabile originale \textit{CGPA} è stata sostituita dalla nuova rappresentazione
    \textit{CGPA\_30}, al fine di evitare ridondanze informative.


    \paragraph{Feature Selection}
    Inizialmente è stata rimossa la feature \textbf {city}: fortemente dipendente dal contesto geografico
    indiano e quindi non generalizzabile ad altri contesti universitari;


    Successivamente, sono state rimosse le feature caratterizzate da una bassa dipendenza dalla variabile target e da
    distribuzioni anomale:

    \begin{itemize}
        \item \textbf {Numeriche}: Work Pressure, Job Satisfaction
        \item \textbf {Categoriali}: Profession
    \end{itemize}

    \subsection{Feature Scaling}
    Per garantire che tutte le feature abbiano la stessa importanza, si è deciso di normalizzare
    le feature numeriche con media 0 e deviazione standard 1 attraverso l'adozione del \textbf{Z-score scaling}.
    Ciò consente di trasformare i dati in una forma che sia uniforme e comparabile, evitando che le variabili
    con valori estremi o unità diverse abbiano un impatto sproporzionato.
    \newline
    Le feature scalate sono:
    \newline \textit{Study Satisfaction, Work/Study Hours, Academic Pressure, Financial Stress e CGPA\_30}.

    \subsection{Encoding}
    Poiché la maggior parte dei modelli di machine learning opera su numeri si è deciso di convertire
    le variabili categoriche in variabili binarie attraverso l'adozione del \textbf{One-Hot encoder}.
    Ciò permette al modello di catturare le differenze tra le categorie senza pregiudizi, trattando ognuna
    come indipendente e riducendo il rischio di interpretare erroneamente le relazioni tra categorie diverse.
    \newline
    Le feature trasformate sono:
    \newline \textit{Gender, Age\_group, Dietary Habits, Family History of Mental Illness, Sleep Duration e Degree\_level}.




\newpage


    \section{Modeling}
    \subsection{Scelta degli Algoritmi}


        Sono stati selezionati due algoritmi di classificazione appartenenti a paradigmi
        differenti: la \textbf{Logistic Regression} e il \textbf{Random Forest}.
        La scelta è motivata dalla necessità di bilanciare accuratezza predittiva e trasparenza
        nell'analisi dei fattori di rischio.

        \paragraph{Logistic Regression}
            La Logistic Regression rappresenta il modello \textit{baseline} per eccellenza nei problemi di
            classificazione binaria. Le ragioni della sua inclusione nel progetto sono le seguenti:
            \begin{itemize}
                \item \textbf{Interpretabilità:} Attraverso l'analisi dei coefficienti $\beta$,
                il modello permette di quantificare l'impatto relativo di ogni feature sulla probabilità del target.
                \item \textbf{Natura Probabilistica:} Il modello restituisce un valore continuo nell'intervallo $[0, 1]$.
                Questo approccio è fondamentale in ambito psicologico per valutare il grado di confidenza della previsione.
                \item \textbf{Ottimizzazione:} Il modello beneficia della standardizzazione delle feature effettuata
                nella pipeline di modelling, garantendo una convergenza efficiente dell'algoritmo di ottimizzazione.
            \end{itemize}



    \paragraph{Random Forest}
    Il Random Forest è un algoritmo di apprendimento supervisionato basato sul principio dell'\textit{ensemble learning}, specificamente seguendo la tecnica del \textit{Bootstrap Aggregating} (o Bagging). Invece di fare affidamento su un singolo modello predittivo, il Random Forest costruisce una vasta collezione di alberi decisionali non correlati per fornire una classificazione più stabile e accurata.
    L'adozione di questa architettura nel presente progetto è motivata dalle seguenti proprietà avanzate:

    \begin{itemize}
        \item \textbf{Riduzione della Varianza tramite Bagging:} Ogni albero della foresta viene addestrato su un sottoinsieme casuale dei dati (campionamento con reinserimento). Questo processo assicura che il modello finale non sia eccessivamente influenzato da specifiche anomalie o rumore presenti nel training set.
        \item \textbf{Feature Randomness:} Durante la creazione di ogni nodo, l'algoritmo seleziona un sottoinsieme casuale di feature. Questa tecnica garantisce la decorrelazione tra gli alberi, aumentando la capacità predittiva globale del sistema.
        \item \textbf{Stima dell'Importanza delle Feature:} Il modello permette di quantificare l'impatto di variabili come \texttt{Academic\_Pressure} o \texttt{Financial\_Stress}, fornendo una gerarchia chiara dei fattori di rischio rilevati nel dataset.
    \end{itemize}

    \subsection{Train-Test Split}

        Per valutare in modo robusto la capacità di generalizzazione dei modelli e ridurre il rischio di
        \textit{overfitting}, è stata adottata la metodologia di \textbf{k-fold cross validation}
        con $k = 5$.
        Questa tecnica prevede la suddivisione del dataset in $k$ sottoinsiemi (fold) di dimensione
        approssimativamente uguale. Per ciascuna iterazione, un fold viene utilizzato come insieme di
        validazione, mentre i restanti $k-1$ fold costituiscono il training set.
        Il processo viene ripetuto $k$ volte, consentendo a ciascun sottoinsieme di essere utilizzato
        esattamente una volta come dati di validazione.


    \subsection{Addestramento}

    L’addestramento dei modelli è stato condotto adottando un approccio \textbf{pipeline-based}, al fine di
    garantire una corretta separazione tra i dati utilizzati per l’apprendimento e quelli impiegati per la
    validazione, evitando fenomeni di \textit{data leakage}.
    In particolare, le operazioni di preprocessing (standardizzazione delle feature e codifica delle
    variabili categoriche) sono state integrate all’interno di una pipeline di
    \textit{scikit-learn} ed eseguite esclusivamente sui dati di training di ciascun fold durante la
    cross-validation.
    Questo approccio assicura che le trasformazioni apprese non siano influenzate dai dati di validazione,
    preservando la correttezza metodologica del processo di addestramento.

    Per entrambi i modelli è stata inoltre adottata una strategia di \textbf{bilanciamento delle classi}
    attraverso l’impostazione del parametro \texttt{class\_weight = balanced}, al fine di mitigare l’effetto
    dello sbilanciamento presente nella variabile target e migliorare la capacità dei modelli di individuare
    correttamente i casi positivi.


    Nel caso del \textbf{Random Forest}, l’addestramento è stato preceduto da una fase di
    \textbf{ottimizzazione degli iperparametri} mediante \textit{Grid Search} (integrata nel processo di
    cross-validation), grazie al quale sono state esplorate diverse configurazioni. Gli iperparametri esplorati sono stati:
    numero di alberi, profondità massima, numero minimo di campioni per foglia. Di seguito le configurazioni ottimali trovate.


    \begin{table}[h]
        \centering
        \begin{tabular}{lcccc}
            \hline
            \textbf{N Estimators} & \textbf{Max Depth} & \textbf{Min Samples Leaf}\\
            \hline
            100 & 20 & 5\\
            \hline
        \end{tabular}


        \caption{Configurazioni ottimali degli iperparametri del Random Forest ottenute tramite Grid Search}
        \label{tab:dt_hyperparameters}
    \end{table}



    Per la \textbf{Logistic Regression}, il processo di addestramento è stato condotto fissando un numero
    contenuto di iterazioni dell’algoritmo di ottimizzazione. In particolare, sono state effettuate
    \textbf{15 iterazioni}, in quanto verifiche empiriche preliminari hanno mostrato la convergenza del
    modello e l’assenza di variazioni apprezzabili nelle prestazioni e nei coefficienti stimati al crescere
    del numero di iterazioni. Tale scelta permette di contenere il costo computazionale senza compromettere
    l’affidabilità del modello.


% ------------------------------------------


    \newpage
    \section{Model Evaluation}
    L'analisi condotta sui due algoritmi di classificazione ha permesso di identificare i fattori più influenti
    nella previsione della depressione studentesca e di selezionare il modello più performante.


    \subsection{Metriche di valutazione}
    Le metriche selezionate per valutare la qualità dei classificatori sono state:
    \begin{itemize}

        \item \textbf{Recall:} Misura la capacità del modello di individuare tutti i casi reali di depressione.
        In ambito medico, è fondamentale massimizzare questa metrica per non ignorare studenti a rischio (pochi falsi negativi).

        \item \textbf{Precision:}  Indica l'affidabilità delle previsioni positive.
        Una precision alta significa che quando il modello prevede "Depressione",
        è molto probabile che lo studente sia effettivamente depresso (pochi falsi positivi).

    \end{itemize}
    \subsection{Valutazioni}
    L'analisi comparativa dei modelli, riassunta nel grafico di performance, evidenzia che
    \textbf{Logistic Regression} offre le prestazioni migliori,
    raggiungendo una \textit{Precision} del \textbf{84.34\%} e una \textit{Recall} di \textbf{79.55\%}.


    \begin{figure}[h!]
        \centering
        \includegraphics[width=1.0\textwidth]{images/graphs/barre} \\
    \end{figure}


    \subsection{La nostra scelta: Logistic Regression}
    Alla luce dei risultati ottenuti, il modello selezionato è stato \textbf{Logistic Regression}.
    Questa scelta garantisce il miglior compromesso tra capacità di generalizzazione
    e affidabilità nelle predizioni positive.


    \subsubsection{Analisi dei Coefficienti Beta ($\beta$)}
    L'analisi dei pesi assegnati dal modello ci permette di comprendere quali variabili influenzano
    maggiormente la decisione.
    I coefficienti con valore assoluto più alto indicano i predittori più forti.
    Di seguito riportiamo le 5 feature più determinanti estratte dal modello finale:


    \begin{table}[h!]
        \centering
        \label{tab:beta_coeffs}
        \renewcommand{\arraystretch}{1.2}
        \begin{tabular}{|l|c|c|l|}

            \hline
            \textbf{Feature} & \textbf{Coeff. ($\beta$)} & \textbf{Odds Ratio}  \\
            \hline
            Age\_group (30+) & -1.30 & 0.27 \\
            Academic Pressure & +1.15 & 3.18 \\
            Dietary Habits (Unhealthy) & +1.08 & 2.96 \\
            Financial Stress & +0.81 & 2.26 \\
            Age\_group (26-29) & -0.53 & 0.58 \\
            \hline

        \end{tabular}
    \end{table}



    \subsection{Analisi di Robustezza e Ottimizzazione del Modello}

    L'accuratezza globale di un modello di Machine Learning può spesso mascherare lacune critiche in specifici sottogruppi della popolazione.
    Per garantire l'equità (\textit{Fairness}) e l'affidabilità clinica del sistema, è stata condotta una valutazione \textbf{Slice-Based}.

    \subsubsection{Identificazione dei Blind Spots}
    L'analisi iniziale è stata eseguita segmentando il dataset in base a caratteristiche demografiche e comportamentali.
    I risultati hanno evidenziato dei significativi \textbf{Punti Ciechi} (\textit{Blind Spots}), ovvero categorie in cui il modello mostrava una \textit{Recall} estremamente bassa,
    fallendo nell'identificare la depressione in assenza di fattori di stress esterni evidenti.
    La seguente figur illustra graficamente i sottogruppi con le performance peggiori.

    \begin{figure}[htbp]
        \centering
        \includegraphics[width=0.95\textwidth]{images/graphs/worstSlices}
        \label{fig:worstSlices}
    \end{figure}

    \newpage

    \subsubsection{Ottimizzazione delle Soglie Decisionali}
    Per correggere questa distorsione, si è proceduto alla ricerca di una \textbf{Soglia Ottimale} specifica per le \textit{slices} critiche identificate nella fase precedente.

    \paragraph{Modifica soglie del modello e Risultati}\newline
    A seguito di una calibrazione custom delle soglie del modello per le slices con performance critiche,
    la rivalutazione ha mostrato un netto recupero della sensibilità nelle categorie precedentemente trascurate.
    I risultati di questo intervento di ottimizzazione sono visibili nella seguente figura, che può essere confrontata direttamente con la situazione iniziale.

    \begin{figure}[htbp]
        \centering
        \includegraphics[width=1\textwidth]{images/graphs/worstSlicesAfterOttimization}
        \label{fig:worstSlicesAfterOttimization}
    \end{figure}

    Performance sulle 'Worst Slices' dopo l'ottimizzazione delle soglie. Si nota un significativo miglioramento della Recall nei gruppi critici rispetto al modello Logistic Regression iniziale.

    \newpage
    \subsubsection{Punti di Forza del Modello}
    Parallelamente, l'analisi ha confermato l'esistenza di punti di forza in cui il modello raggiunge performance prossime alla perfezione.
    Questi segmenti corrispondono generalmente a individui soggetti a carichi di stress molto elevati, dove i segnali predittivi sono chiari e dominanti.

    Le \textit{slice} migliori includono tipicamente valori di \textit{Academic Pressure} e \textit{Financial Stress} pari al massimo della scala (5.0).
    Ciò dimostra come il modello abbia appreso correttamente la correlazione diretta tra stress estremo e patologia, tendendo però a sovra-utilizzarla come principale chiave di lettura.
    La distribuzione di queste performance eccellenti è riportata di seguito.

    \begin{figure}[htbp]
        \centering
        \includegraphics[width=1\textwidth]{images/graphs/bestSlicesAfterOttimization}
        \label{fig:bestSlicesAfterOttimization}
    \end{figure}

    Analisi delle 'Best Slices' del modello ottimizzato. I segmenti mostrati raggiungono performance quasi perfette, corrispondenti prevalentemente a scenari di alto stress percepito.


    \subsection{Confronto Globale e Validazione Finale}
    Per validare l'efficacia dell'intero processo di ottimizzazione, è stato realizzato un confronto diretto tra i modelli baseline (\textit{Random Forest},
    \textit{Logistic Regression} standard) e il modello finale \textbf{Logistic Regression (Custom Thresholds)}.
    L'esito di questo confronto comparativo è sintetizzato nel grafico sottostante.

    \begin{figure}[htbp]
        \centering
        \includegraphics[width=0.8\textwidth]{images/graphs/performanceAfterOttimization}
        \label{fig:performanceAfterOttimization}
    \end{figure}


    Come evidenziato dal grafico, il modello ottimizzato mostra una \textit{Recall} e un \textit{F1-Score} superiori, non solo nelle categorie critiche, ma stabilizzando le performance sull'intero dataset.

    Alla luce dei risultati ottenuti, il modello selezionato per la fase di deployment è \textbf{Logistic Regression (Custom Thresholds)}.

    \newpage

    Infine, per valutare nel dettaglio la tipologia di errori commessi dal modello finale, riportiamo la Matrice di Confusione.
    Essa mostra la distribuzione tra predizioni corrette (sulla diagonale principale) ed errori di classificazione.

    \begin{figure}[htbp]
        \centering
        \includegraphics[width=0.75\textwidth]{images/graphs/finalConfusionMatrix}
        \label{fig:finalConfusionMatrix}
    \end{figure}

    Il modello dimostra una solida capacità di distinguere le classi, minimizzando efficacemente i Falsi Negativi (alta Recall).
    Questa caratteristica è fondamentale in ambito clinico per ridurre il rischio di ignorare studenti che necessitano di supporto, anche a costo di un leggero aumento dei Falsi Positivi.



% -------------------------------------------------------------------------


    \newpage
    \section{Interfaccia della Demo}
    \paragraph{Pagina Iniziale}


    La pagina di benvenuto presenta un pulsante per accedere ad un questionario.

    \begin{figure}[h]
        \centering
        \includegraphics[width=1\textwidth]{images/index}
        \label{fig:index_demo}
    \end{figure}


    \paragraph{Il Questionario di Input}
    L'interfaccia di inserimento dati consiste in un modulo da compilare.
    In seguito è presente un esempio di compilazione del questionario.

    \begin{figure}[h]
        \centering
        \includegraphics[width=1\textwidth]{images/form1}
        \label{fig:form1_demo}
    \end{figure}



    \newpage
    \begin{figure}[h]
        \centering
        \rightmargin
        \includegraphics[width=1\textwidth]{images/form2}
        \label{fig:form2_demo}
    \end{figure}


    \paragraph{Visualizzazione del Risultato}
    Una volta completata la compilazione e inviato il modulo, il sistema effettua una chiamata al backend
    dove risiede il modello di classificazione. \newline Il risultato dell'inferenza viene mostrato in una pagina di output dedicata che presenta:

    \begin{enumerate}
        \item \textbf{Esito della Classificazione}.
        \item \textbf{Componente Visiva:} L'interfaccia utilizza una comunicazione visiva per rendere il responso facilmente interpretabile dall'utente finale.
    \end{enumerate}


    In seguito è riportato il risultato relativo alla compilazione del \hyperref[fig:form1_demo] {\underline{form}} visto in precedenza.


    \begin{figure}[h]
        \centering
        \includegraphics[width=1\textwidth]{images/risultato}
        \label{fig:risultato_demo}
    \end{figure}


\end{document}

